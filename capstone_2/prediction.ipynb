{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load helpers.py\n",
    "from pyspark.ml.classification import LogisticRegression, NaiveBayes, DecisionTreeClassifier, GBTClassifier, \\\n",
    "    RandomForestClassifier\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from pyspark.sql.functions import current_date, expr, datediff, to_date\n",
    "from pyspark.sql.functions import length, regexp_replace\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def get_kv_pairs(row, exclusions=[]):\n",
    "    # get the text from the row entry\n",
    "    text = str(row.review_body).lower()\n",
    "    # create blacklist of words\n",
    "    blacklist = set(stopwords.words('english'))\n",
    "    # add explicit words\n",
    "    [blacklist.add(i) for i in exclusions]\n",
    "    # extract all words\n",
    "    words = re.findall(r'([^\\w+])', text)\n",
    "    # for each word, send back a count of 1\n",
    "    # send a list of lists\n",
    "    return [[w, 1] for w in words if w not in blacklist]\n",
    "\n",
    "\n",
    "def get_word_counts(texts, exclusions=[]):\n",
    "    mapped_rdd = texts.rdd.flatMap(lambda row: get_kv_pairs(row, exclusions))\n",
    "    counts_rdd = mapped_rdd.reduceByKey(lambda a, b: a + b).sortByKey(True, 1)\n",
    "    return counts_rdd.collect()\n",
    "\n",
    "\n",
    "def convert_str_to_int(df, col='verified_purchase', type_='int'):\n",
    "    return df.select((df[col] == 'Y').cast(type_))\n",
    "\n",
    "\n",
    "def get_review_age(df):\n",
    "    return df.select(datediff(current_date(), to_date(df['review_date'])))\n",
    "\n",
    "\n",
    "def prepare_features(df):\n",
    "    df = df.withColumn('exclam', length('review_body') - length(regexp_replace('review_body', '\\!', '')))\n",
    "    df = df.withColumn('age', datediff(current_date(), to_date(df['review_date'])))\n",
    "    df = df.withColumn('review_length', length(df['review_body']))\n",
    "    df = df.withColumn('helfulness', df['helpful_votes'] / df['total_votes'])\n",
    "    df = df.withColumn('label', expr(\"CAST(verified_purchase='Y' As INT)\"))\n",
    "    select_cols = df.select(['star_rating', 'helfulness', 'age', 'review_length', 'label']).na.fill(0)\n",
    "    return select_cols\n",
    "\n",
    "\n",
    "def split_data(df, rate=.9):\n",
    "    training = df.sampleBy(\"label\", fractions={0: rate, 1: rate}, seed=12)\n",
    "    return training, df.subtract(training)\n",
    "\n",
    "\n",
    "def get_auc_roc(classifier, training, test):\n",
    "    model = classifier.fit(training)\n",
    "    out = model.transform(test) \\\n",
    "        .select(\"prediction\", \"label\") \\\n",
    "        .rdd.map(lambda x: (float(x[0]), float(x[1])))\n",
    "    metrics = BinaryClassificationMetrics(out)\n",
    "    print(\"Model: {1}. Area under ROC: {0:2f}\".format(metrics.areaUnderROC, clf.__class__))\n",
    "    return model, out, metrics\n",
    "\n",
    "\n",
    "def get_vectorized_features(df, cols=['star_rating']):\n",
    "    va = VectorAssembler().setInputCols(cols).setOutputCol(\n",
    "        'features')\n",
    "    return va.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load environment.py\n",
    "from pyspark.ml.classification import LogisticRegression, NaiveBayes, DecisionTreeClassifier, GBTClassifier, \\\n",
    "    RandomForestClassifier\n",
    "import pyspark as ps\n",
    "from pyspark.sql.types import StructField, StructType, StringType, IntegerType\n",
    "\n",
    "DATA_FILE = '../../amazon_reviews_us_Camera_v1_00.tsv.gz'\n",
    "APP_NAME = 'Prediction'\n",
    "FEATURES = ['star_rating', 'review_body', 'helpful_votes', 'total_votes', 'verified_purchase', 'review_date']\n",
    "SAMPLE_SIZE = 10000\n",
    "\n",
    "review_schema = StructType(\n",
    "    [StructField('marketplace', StringType(), True),\n",
    "     StructField('customer_id', StringType(), True),\n",
    "     StructField('review_id', StringType(), True),\n",
    "     StructField('product_id', StringType(), True),\n",
    "     StructField('product_parent', StringType(), True),\n",
    "     StructField('product_title', StringType(), True),\n",
    "     StructField('product_category', StringType(), True),\n",
    "     StructField('star_rating', IntegerType(), True),\n",
    "     StructField('helpful_votes', IntegerType(), True),\n",
    "     StructField('total_votes', IntegerType(), True),\n",
    "     StructField('vine', StringType(), True),\n",
    "     StructField('verified_purchase', StringType(), True),\n",
    "     StructField('review_headline', StringType(), True),\n",
    "     StructField('review_body', StringType(), True),\n",
    "     StructField('review_date', StringType(), True)])\n",
    "\n",
    "spark = (ps.sql.SparkSession.builder\n",
    "         .master(\"local[1]\")\n",
    "         .appName(APP_NAME)\n",
    "         .getOrCreate()\n",
    "         )\n",
    "sc = spark.sparkContext\n",
    "\n",
    "df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"sep\", \"\\t\") \\\n",
    "    .schema(review_schema) \\\n",
    "    .load(DATA_FILE)\n",
    "\n",
    "review_all = df.select(FEATURES)\n",
    "review_sample = df.select(FEATURES).limit(SAMPLE_SIZE).cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [LogisticRegression(), NaiveBayes(), DecisionTreeClassifier(), RandomForestClassifier(),\n",
    "                   GBTClassifier()]\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10000 sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    0|  739|\n",
      "|    1|  731|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "select_cols = prepare_features(review_sample)\n",
    "features = get_vectorized_features(select_cols, cols=['star_rating', 'helfulness', 'age', 'review_length'])\n",
    "training = features.sampleBy(\"label\", fractions={0: 0.92, 1: 0.08}, seed=12)\n",
    "# training = features.sample(True, 0.5, 42)\n",
    "training.groupBy(\"label\").count().orderBy(\"label\").show()\n",
    "test = features.subtract(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: <class 'pyspark.ml.classification.LogisticRegression'>. Area under ROC: 0.666389\n",
      "Model: <class 'pyspark.ml.classification.NaiveBayes'>. Area under ROC: 0.683751\n",
      "Model: <class 'pyspark.ml.classification.DecisionTreeClassifier'>. Area under ROC: 0.662692\n",
      "Model: <class 'pyspark.ml.classification.RandomForestClassifier'>. Area under ROC: 0.659492\n",
      "Model: <class 'pyspark.ml.classification.GBTClassifier'>. Area under ROC: 0.660202\n"
     ]
    }
   ],
   "source": [
    "for clf in classifiers:\n",
    "    model, out, metrics = get_auc_roc(clf, training, test)\n",
    "    results.append([model, out, metrics])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_cols = prepare_features(review_all)\n",
    "features = get_vectorized_features(select_cols, cols=['star_rating', 'helfulness', 'age', 'review_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|label|  count|\n",
      "+-----+-------+\n",
      "|    0| 307573|\n",
      "|    1|1494401|\n",
      "+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features.groupBy(\"label\").count().orderBy(\"label\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training = features.sampleBy(\"label\", fractions={0: 0.9, 1: 0.1}, seed=24)\n",
    "training = features.sample(True, 0.5, 42)\n",
    "# training.groupBy(\"label\").count().orderBy(\"label\").show()\n",
    "test = features.subtract(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf in classifiers:\n",
    "    model, out, metrics = get_auc_roc(clf, training, test)\n",
    "    results.append([model, out, metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
